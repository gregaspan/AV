version: '3'
services:
  namenode:
    image: apache/hadoop:3.4.1
    container_name: namenode
    hostname: namenode
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./namenode:/opt/hadoop/data/nameNode
      - ./config:/opt/hadoop/etc/hadoop
      - ./start-hdfs.sh:/start-hdfs.sh
    ports:
      - "9870:9870"
    command: [ "/bin/bash", "/start-hdfs.sh" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.2
    restart: always

  datanode1:
    image: apache/hadoop:3.4.1
    container_name: datanode1
    hostname: datanode1
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./datanode1:/opt/hadoop/data/dataNode
      - ./config:/opt/hadoop/etc/hadoop
      - ./init-datanode.sh:/init-datanode.sh
    depends_on:
      - namenode
    command: [ "/bin/bash", "/init-datanode.sh" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.3
    restart: always

  datanode2:
    image: apache/hadoop:3.4.1
    container_name: datanode2
    hostname: datanode2
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./datanode2:/opt/hadoop/data/dataNode
      - ./config:/opt/hadoop/etc/hadoop
      - ./init-datanode.sh:/init-datanode.sh
    depends_on:
      - namenode
    command: [ "/bin/bash", "/init-datanode.sh" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.4
    restart: always

  datanode3:
    image: apache/hadoop:3.4.1
    container_name: datanode3
    hostname: datanode3
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./datanode3:/opt/hadoop/data/dataNode
      - ./config:/opt/hadoop/etc/hadoop
      - ./init-datanode.sh:/init-datanode.sh
    depends_on:
      - namenode
    command: [ "/bin/bash", "/init-datanode.sh" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.5
    restart: always

  resourcemanager:
    image: apache/hadoop:3.4.1
    container_name: resourcemanager
    hostname: resourcemanager
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    ports:
      - "8088:8088"
    command: [ "/bin/bash", "-c", "yarn resourcemanager" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.11
    restart: always

  nodemanager:
    image: apache/hadoop:3.4.1
    container_name: nodemanager
    hostname: nodemanager
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    command: [ "/bin/bash", "-c", "yarn nodemanager" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.12
    restart: always

  jobhistory:
    image: apache/hadoop:3.4.1
    container_name: jobhistory
    hostname: jobhistory
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
    volumes:
      - ./config:/opt/hadoop/etc/hadoop
    ports:
      - "19888:19888"
    command: [ "/bin/bash", "-c", "mapred historyserver" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.13
    restart: always

  sqoop:
    image: my-sqoop:latest
    container_name: sqoop
    environment:
      - HADOOP_HOME=/opt/hadoop
      - HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop
      - SQOOP_HOME=/opt/sqoop
    command: [ "/bin/bash", "-c", "echo 'Sqoop container started'; while true; do sleep 3600; done" ]
    networks:
      hadoop_shared_net:
        ipv4_address: 172.31.0.10
    restart: always

networks:
  hadoop_shared_net:
    external: true